<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>énoncé</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="/home/fabrice/note/gfm.css" />
</head>
<body>
<h1 id="tp3">TP3</h1>
<p>This assignment focuses on the NLP task known as named entity recognition (NER), which consists in identifying the spans that refer to specific real-world entities, as opposed to common words, which denote classes (or categories) of phenomena. For instance, university is a common word which denotes all higher-education institutions where multiple disciplines are studied and taught, but the span University of Geneva refers to a single, particular entity that exists in the real world.</p>
<p>We will work with annotated data in several languages using two Python libraries.</p>
<h3 id="data">Data</h3>
<p>We use one data set per language, in particular:</p>
<ul>
<li>UNER_Portuguese-Bosque</li>
<li>UNER_Chinese-GSDSIMP</li>
<li>UNER_Swedish-Talbanken</li>
<li>UNER_Serbian-SET</li>
<li>UNER_Slovak-SNK</li>
<li>UNER_Croatian-SET</li>
<li>UNER_English-EWT</li>
<li>UNER_Danish-DDT</li>
</ul>
<h3 id="tools">Tools</h3>
<ul>
<li>spaCy is a general NLP tool that can perform various tasks including NER</li>
<li>python-crfsuite is a more specific tool for sequence classification, most commonly used for NER</li>
</ul>
<h3 id="what-to-do">What to do</h3>
<p>Your task is to find the appropriate way to use the two libraries and make NER predictions for the test portion of each data set. You will compare the output of the models with the gold labels given in the data and print one full classification report with the F-score evaluation per language and per tool. The reprot should contain per-class and overall performance. Save all the spaCy reports in the text file spacy_rerports.txt and the CRF reports in crf_reports.txt.</p>
<p>For creating classification reports, you can use sklearn or your own functions. Submit to moodle as a ZIP archive:</p>
<ul>
<li>Script 1 named spacy_tp3.py<br />
</li>
<li>Script 2 named crf_tp3.py</li>
<li>spacy_rerports.txt</li>
<li>crf_reports.txt</li>
<li>README.txt containing the following (and in this order)
<ol type="1">
<li>instructions for running your scripts</li>
<li>running time for both scripts</li>
<li>options selected for running spaCy</li>
</ol></li>
</ul>
</body>
</html>
